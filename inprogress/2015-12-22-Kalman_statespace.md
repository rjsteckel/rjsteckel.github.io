@def title = "Kalman State Space"

Kalman filtering is a popular tool for adaptive estimation of time-series through noisy measurements. Initially, Kalman filtering started in electrical engineering, but it has found its way into economics, machine learning, finance and many other fields. In 1960 R.E. Kalman wrote a paper that expanded Wiener filtering to include state space methods and perform on-line, recursive computations versus a batch analysis.

Kalman filtering estimates what the optimal values of a measurement should be given noisy measurements. These estimates can also then be used for Kalman smoothing and forecasting. Part of the power of the Kalman Filter is the generality. Higher order modeling equations can be broken down into multiple first order equations. But before filtering the data, a state space model that defines the dynamics of the system is required. Once the correct state space model is defined, the Kalman filter application is straight-forward to apply. Because it is possible to define time-variant state space models, they are quite flexible, even when non-stationarity exists. Besides defining the state space equation, a second difficulty is estimating the parameters for the model. However, these are typically solved numerically and come with their own difficulties, but because the Kalman filtering model is Gaussian, standard MLE estimates of the Gaussian likelihood can be used.

The state space model defines the underlying dynamics of the system. Often times, it can be difficult to define the correct state space model when using the Kalman filter. Typically, domain knowledge must be incorporated into the state space model for good performance. State space model literature usually begins with a model called the local level model. This is one of the simplest state space models (with no trend or seasonality), but it is applied quite often.

Autoregressive (AR) and moving average (MA) models can be considered a subset of state space methods. Both of these models can be encoded in state space equations. Unlike ARMA models, state space models do not require that non-stationary time series be transformed using differencing.

Here the and matrices are assumed to be known during filtering. Often they are time invariant and the subscript is dropped. These matrices can be used for deterministic transformations on the state. These can allow the Kalman filter to model more complicated systems that have seasonal and periodic behavior.

However, before we could proceed to use this model, we would need a few parameters first. First, we need the variance parameters. Since the Kalman filter makes the assumption of zero mean Gaussian noise terms, a fairly straight forward likelihood function can be found. Once, we have a likelihood, we can numerically estimate the variance parameters (described later). But besides the variances parameters, we also need initial values to begin the recursive computations. The first estimates of the Kalman filter are typically poor and have a large error. So, less work is put into computing good starting values. In fact, often they are chosen to be 1. The adaptive nature of the Kalman filter quickly adapts to computing optimal values. Some other assumptions are required as well. The Kalman filter assumes that the variances parameters are uncorrelated each other, as well as, contain no autocorrelation. It also assumes that the variance parameters are uncorrelated with the initial values.

In the next post, I'll look at the actual filtering equations.